# -*- coding: utf-8 -*-
"""Hrushikesh Sahu-Team 1- Capstone Project 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fC31hWaLhBGm2JLx0x3GpERq-pXuSTi0

# <b><u> Project Title : Predicting the effectiveness of bank marketing campaigns </u></b>

## <b> Problem Description </b>

### The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. The classification goal is to predict if the client will subscribe a term deposit (variable y).

## <b> Data Description </b>

## <b>Input variables: </b>
### <b> Bank Client data: </b>

* ### age (numeric)
* ### job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')
* ### marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
* ### education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')
* ### default: has credit in default? (categorical: 'no','yes','unknown')
* ### housing: has housing loan? (categorical: 'no','yes','unknown')
* ### loan: has personal loan? (categorical: 'no','yes','unknown')

### <b> Related with the last contact of the current campaign:</b>
* ### contact: contact communication type (categorical: 'cellular','telephone')
* ### month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')
* ### day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')
* ### duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.

### <b>Other attributes: </b>
* ### campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
* ### pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
* ### previous: number of contacts performed before this campaign and for this client (numeric)
* ### poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')

### <b> Social and economic context attributes </b>
* ### emp.var.rate: employment variation rate - quarterly indicator (numeric)
* ### cons.price.idx: consumer price index - monthly indicator (numeric)
* ### cons.conf.idx: consumer confidence index - monthly indicator (numeric)
* ### euribor3m: euribor 3 month rate - daily indicator (numeric)
* ### nr.employed: number of employees - quarterly indicator (numeric)

### <b>Output variable (desired target):</b>
* ### y - has the client subscribed a term deposit? (binary: 'yes','no')
"""

# Commented out IPython magic to ensure Python compatibility.

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix
import xgboost as xgb
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import train_test_split
from sklearn import ensemble

# %matplotlib inline
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv('/content/drive/MyDrive/AlmaBetter/Cohort Aravali/Module 4/Week 2/bank-full.csv',sep=';')

df.head()

df.shape

"""###our data set have 45211 have rows and 17 columns"""

# duplicate
len(df[df.duplicated()])

"""### No duplicate value in our dataset"""

list(df.columns)

"""columns names of our dataset are ['age',
 'job',
 'marital',
 'education',
 'default',
 'balance',
 'housing',
 'loan',
 'contact',
 'day',
 'month',
 'duration',
 'campaign',
 'pdays',
 'previous',
 'poutcome',
 'y']
"""

df.info()

"""##No null value in our dataset"""

df.describe()

"""##maximum balance is vary high as compair to 75 percentile of balance """

target_y=df['y'].value_counts().reset_index()
target_y.rename(columns={'index':'class_label'},inplace=True)
target_y.rename(columns={'y':'count'},inplace=True)
target_y

plt.figure(figsize=(13,9))
plt.title('Count of target variable')
sns.barplot(x='class_label',y='count',data=target_y)

"""###most of the obsarvation have No value but very few observation have yes value that means our class label is imbalanced"""



job_df=df['job'].value_counts().reset_index()
job_df.rename(columns={'index':'job_type'},inplace=True)
job_df.rename(columns={'job':'Number_of_job'},inplace=True)
job_df

plt.figure(figsize=(20,13))
plt.title('Job vs Number_of_job')
sns.barplot(x='job_type',y='Number_of_job',data=job_df)

"""### most of the  people have blue-collar  and management job
### least number of people  have student and unknown
"""

marital_df=df['marital'].value_counts().reset_index()
marital_df.rename(columns={'index':'marital_status'},inplace=True)
marital_df.rename(columns={'marital':'Number_of_person'},inplace=True)
marital_df

plt.figure(figsize=(15,11))
plt.title('Person marital status')
sns.barplot(x='marital_status',y='Number_of_person',data=marital_df)

"""###from this graph we can observe that most of the people are married  and least number of people have divorced"""

education_df=df['education'].value_counts().reset_index()
education_df.rename(columns={'index':'education_type'},inplace=True)
education_df.rename(columns={'education':'Number_of_people'},inplace=True)
education_df

plt.figure(figsize=(15,11))
plt.title('Number of person vs education')
sns.barplot(x='education_type',y='Number_of_people',data=education_df)

"""### from this graph we can observed that most of the people have secondry and tertiary education and very few people have primary education"""

default_df=df['default'].value_counts().reset_index()
default_df.rename(columns={'index':'type'},inplace=True)
default_df.rename(columns={'default':'default_count'},inplace=True)
default_df

plt.figure(figsize=(15,11))
plt.title('Count of Default')
sns.barplot(x='type',y='default_count',data=default_df)

housing_df=df['housing'].value_counts().reset_index()
housing_df.rename(columns={'index':'is_housing'},inplace=True)
housing_df.rename(columns={'housing':'Count_of_housing'},inplace=True)
housing_df

plt.figure(figsize=(15,11))
plt.title('Check for house lone')
sns.barplot(x='is_housing',y='Count_of_housing',data=housing_df)

"""###**from above graph we can see that most of the people have house lone**"""

loan_df=df['loan'].value_counts().reset_index()
loan_df.rename(columns={'index':'is_lone'},inplace=True)
loan_df.rename(columns={'loan':'Count_of_lone'},inplace=True)
loan_df

plt.figure(figsize=(13,9))
plt.title('How many have Lone')
sns.barplot(x='is_lone',y='Count_of_lone',data=loan_df)

"""##from above graph we can see that most of the people have No lone"""

contact_df=df['contact'].value_counts().reset_index()
contact_df.rename(columns={'index':'contact_type'},inplace=True)
contact_df.rename(columns={'contact':'Number_of_person'},inplace=True)
contact_df

plt.figure(figsize=(15,11))
plt.title('Contact type vs Number_of_people')
sns.barplot(x='contact_type',y='Number_of_person',data=contact_df)

"""###from this graph we can observed that most of the contact type are cellular and least number of contact type are telephone"""

month_df=df['month'].value_counts().reset_index()
month_df.rename(columns={'index':'month_type'},inplace=True)
month_df.rename(columns={'month':'Number_of_call'},inplace=True)
month_df

plt.figure(figsize=(15,11))
plt.title('Month vs numbers of call')
sns.barplot(x='month_type',y='Number_of_call',data=month_df)

"""##in the month of may they  have tried to contact more number of pople  but in the month of dec they have contact vary less number of people"""

campaign_df=df['campaign'].value_counts().reset_index()
campaign_df

day_df=df['day'].value_counts().reset_index()
day_df.rename(columns={'index':'day_type'},inplace=True)
day_df.rename(columns={'day':'Number_of_call'},inplace=True)
day_df

plt.figure(figsize=(15,11))
plt.title('day_type vs Number_of_call')
sns.barplot(x='day_type',y='Number_of_call',data=day_df)

"""## from this graph we can see that in day 20 we have most number of call"""

poutcome_df=df['poutcome'].value_counts().reset_index()
poutcome_df.rename(columns={'index':'poutcome_type'},inplace=True)
poutcome_df.rename(columns={'poutcome':'count_of_poutcome'},inplace=True)
poutcome_df

plt.figure(figsize=(15,11))
plt.title('poutcome_type vs count_of_poutcome')
sns.barplot(x='poutcome_type',y='count_of_poutcome',data=poutcome_df)

"""## poutcome is unknown in most of the cases"""

pdays_df=df['pdays'].value_counts().reset_index()
pdays_df

previous_df=df['previous'].value_counts().reset_index()
previous_df

df.head()

df.tail()

# Independent variable 'age'
plt.figure(figsize=(15,10))
plt.title('Distribution of age')
sns.distplot(df['age'],color="B")

# Independent variable 'age'
plt.figure(figsize=(15,10))
plt.title('Log Distribution of age')
sns.distplot(np.log10(df['age']),color="B")

# Independent variable 'balance'
plt.figure(figsize=(15,10))
plt.title('Distribution of balance')
sns.distplot(df['balance'],color="B")

# Independent variable 'duration'
plt.figure(figsize=(15,10))
plt.title('Log Distribution of duration')
sns.distplot(df['duration'],color="B")

# Independent variable 'campaign'
plt.figure(figsize=(15,10))
plt.title('Distribution of campaign')
sns.distplot(df['campaign'],color="B")

# Independent variable 'day'
plt.figure(figsize=(15,10))
plt.title('Log Distribution of day')
sns.distplot(df['day'],color="B")

# Independent variable 'pdays'
plt.figure(figsize=(15,10))
plt.title('Distribution of pdays')
sns.distplot(df['pdays'],color="B")

# Independent variable 'previous'
plt.figure(figsize=(15,10))
plt.title('Distribution of previous')
sns.distplot(df['previous'],color="B")

def plot_cat_data(df,dep_var):
  cat_columns = list(set(df.describe().columns)^set(df.columns))
  cat_columns.remove(dep_var)
  for i,e in enumerate(cat_columns):
    plt.figure(i)
    ax = sns.countplot(df[e],hue=df[dep_var])
    for p in ax.patches:
      height = p.get_height()
      ax.text(p.get_x()+p.get_width()/2.,
              height + 3,
              '{:1.2f}'.format(height/df.shape[0]),
              ha="center")
    if(len(ax.patches)>10):
      plt.xticks(rotation=90)  
    plt.title(f'Count Plot for {e}')
    plt.show()

plot_cat_data(df,'y')

df.tail(20)

df.head()

"""##convert pdays to binary type """

def pdays_contact(days):
  if days == -1:
    return 0
  else:
    return 1

df['is_contacted_bef'] = df['pdays'].apply(pdays_contact)

"""#**One hot encoding of some selected categorical variable**"""

# One hot encoding
df = pd.get_dummies(df, columns=["job", "marital","education",'default','housing','loan','contact','poutcome'], prefix=["job", "marital","education",'default','housing','loan','contact','poutcome'])

"""#**Convert target variable y into Binary**"""

df['y'] = df['y'].apply(lambda x : 1 if x=='yes' else 0 )

df.drop(['month','duration','age','day'],axis=1,inplace=True)

"""##try to drop month ,duration,age and day because they are not important"""

df.head()

"""#**IQR=Q3-Q1**

#**lower_limit_outlier=Q1-1.5*IQR**

#**upper_limit_outlier=Q3+1.5*IQR**

##**so we have to take the values which is greater then lower limit outlier and less then upper limit outlier**
"""

plt.figure(figsize=(15,11))
plt.title("Box plot of  balance ")
ax = sns.boxplot(data=df['balance'], orient="v")

"""##from above graph we can see that our balance columns have some outlier.so we have to remove them"""

#percentile_q1_balance = np.percentile(df['balance'],25)
#print(percentile_q1_balance)
#percentile_q2_balance = np.percentile(df['balance'],50)
#print(percentile_q2_balance)
#percentile_q3_balance = np.percentile(df['balance'],75)
#print(percentile_q3_balance)

#iqr=percentile_q3_balance - percentile_q1_balance
#lower_limit_outlier=percentile_q1_balance-1.5*iqr
#upper_limit_outlier=percentile_q3_balance+1.5*iqr

#print("lower limit for outlier  :",lower_limit_outlier)
#print("Upper limit for outlier  :",upper_limit_outlier)

#df=df[df['balance']>lower_limit_outlier]
#df=df[df['balance']<upper_limit_outlier]

plt.figure(figsize=(15,8))
plt.title("Box plot of  campaign ")
ax = sns.boxplot(data=df['campaign'], orient="v")

#percentile_q1_campaign = np.percentile(df['campaign'],25)
#print(percentile_q1_campaign)
#percentile_q2_campaign = np.percentile(df['campaign'],50)
#print(percentile_q2_campaign)
#percentile_q3_campaign = np.percentile(df['campaign'],75)
#print(percentile_q3_campaign)

#iqr=percentile_q3_campaign - percentile_q1_campaign
#lower_limit_outlier=percentile_q1_campaign-1.5*iqr
#upper_limit_outlier=percentile_q3_campaign+1.5*iqr

#print("lower limit for outlier  :",lower_limit_outlier)
#print("Upper limit for outlier  :",upper_limit_outlier)

#df=df[df['campaign']>lower_limit_outlier]
#df=df[df['campaign']<upper_limit_outlier]

"""#**Remove the outlier using IsolationForest**"""

feature_df = df.drop(['y'],axis=1)
from sklearn.ensemble import IsolationForest
anomaly_filter = IsolationForest(contamination=0.1,n_jobs=-1)
anomalies = pd.Series(anomaly_filter.fit_predict(feature_df))
df['is_anomaly'] = anomalies
final_df = df[df['is_anomaly']==1].drop(['is_anomaly'],axis=1)

final_df.head()

"""#**Scaleing the dataset using MinMaxScaler**"""

from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
final_df_scaled = pd.DataFrame(mms.fit_transform(final_df.drop('y',axis=1).values),columns=final_df.drop('y',axis=1).columns)

final_df_scaled.head()

final_df_scaled.tail()

final_df_scaled.shape

final_df_scaled

final_df_scaled['y'] = final_df.y

final_df_scaled =final_df_scaled[~final_df_scaled.isin([np.nan, np.inf, -np.inf]).any(1)]

X1=final_df_scaled.drop(['y'],axis=1)

"""##Over sampling  the data using SMOTE"""

from imblearn.over_sampling import SMOTE
sampler = SMOTE()
X,y = sampler.fit_resample(final_df_scaled.drop(['y'],axis=1).values,final_df_scaled['y'].values)

"""#**Train_Test_split**"""

# Importing train_test_split
from sklearn import preprocessing 
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2,random_state=42)

print(X_train.shape,Y_train.shape)
print(X_test.shape,Y_test.shape)

"""#**Applying RandomForestClassifier to our DataSet**"""

# Number of trees
n_estimators = [50,80,100]

# Maximum depth of trees
max_depth = [4,6,8]

# Minimum number of samples required to split a node
min_samples_split = [50,100,150]

# Minimum number of samples required at each leaf node
min_samples_leaf = [40,50]

# HYperparameter Grid
param_dict = {'n_estimators' : n_estimators,
              'max_depth' : max_depth,
              'min_samples_split' : min_samples_split,
              'min_samples_leaf' : min_samples_leaf}

# Create an instance of the RandomForestClassifier
rf_model = RandomForestClassifier()

# Grid search
rf_grid = GridSearchCV(estimator=rf_model,
                       param_grid = param_dict,
                       cv = 5, verbose=2, scoring='roc_auc')

rf_grid.fit(X_train,Y_train)

rf_grid.best_estimator_

rf_optimal_model = rf_grid.best_estimator_

rf_optimal_model.score

rf_grid.best_params_

# Making predictions on train and test data

train_class_preds = rf_optimal_model.predict(X_train)
test_class_preds = rf_optimal_model.predict(X_test)


# Get the probabilities on train and test
train_preds = rf_optimal_model.predict_proba(X_train)[:,1]
test_preds = rf_optimal_model.predict_proba(X_test)[:,1]

# Calculating accuracy on train and test
train_accuracy = accuracy_score(Y_train,train_class_preds)
test_accuracy = accuracy_score(Y_test,test_class_preds)

print("The accuracy on train dataset is", train_accuracy)
print("The accuracy on test dataset is", test_accuracy)

# Get the roc_auc score for train and test dataset
train_auc = roc_auc_score(Y_train,train_preds)
test_auc = roc_auc_score(Y_test,test_preds)

print('Train roc_auc= ',train_auc)
print('Test roc_auc= ',test_auc)

train_auc

test_auc

# Get the confusion matrices for train and test
train_cm = confusion_matrix(Y_train,train_class_preds)
test_cm = confusion_matrix(Y_test,test_class_preds )

train_cm

#confusion matrix for train data set
sns.heatmap(train_cm/np.sum(train_cm), annot=True, 
            fmt='.2%', cmap='Blues')

test_cm

#confusion matrix for train data set
sns.heatmap(test_cm/np.sum(test_cm), annot=True, 
            fmt='.2%', cmap='Blues')

X1.columns

rf_optimal_model.feature_importances_

importances = rf_optimal_model.feature_importances_

importance_dict = {'Feature' : list(X1.columns),
                   'Feature Importance' : importances}

importance_df = pd.DataFrame(importance_dict)

importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)

new_df=importance_df.sort_values(by=['Feature Importance'],ascending=False)
new_df

plt.figure(figsize=(20,20))
plt.title(' features importance')
sns.barplot(x='Feature Importance',y="Feature",data=new_df)

"""#**Applying XGboost algorithem to our DataSet**"""

# Number of trees
n_estimators = [50,80,100,120]

# Maximum depth of trees
max_depth = [3,5,7]

learning_rate=[0.1,0.3,0.5]

# HYperparameter Grid
param_xgb = {'n_estimators' : n_estimators,
              'max_depth' : max_depth,
              'learning_rate':learning_rate}

# Create an instance of the  XGBClassifier
xgb_model = xgb.XGBClassifier()

# Grid search
xgb_grid = GridSearchCV(estimator=xgb_model,param_grid = param_xgb,cv = 5, verbose=2, scoring='roc_auc')

xgb_grid.fit(X_train,Y_train)

xgb_grid.best_params_

xgb_grid.best_estimator_

xgb_optimal_model = xgb_grid.best_estimator_

# Making predictions on train and test data

xgb_train_class_preds = xgb_optimal_model.predict(X_train)
xgb_test_class_preds = xgb_optimal_model.predict(X_test)


# Get the probabilities on train and test
xgb_train_preds = xgb_optimal_model.predict_proba(X_train)[:,1]
xgb_test_preds = xgb_optimal_model.predict_proba(X_test)[:,1]

# Calculating accuracy on train and test
xgb_train_accuracy = accuracy_score(Y_train,xgb_train_class_preds)
xgb_test_accuracy = accuracy_score(Y_test,xgb_test_class_preds)

print("The accuracy on train dataset is", xgb_train_accuracy)
print("The accuracy on test dataset is", xgb_test_accuracy)

# Get the confusion matrices for train and test
xgb_train_cm = confusion_matrix(Y_train,xgb_train_class_preds)
xgb_test_cm = confusion_matrix(Y_test,xgb_test_class_preds )

xgb_train_cm

#confusion matrix for train data set
sns.heatmap(xgb_train_cm/np.sum(xgb_train_cm), annot=True, 
            fmt='.2%', cmap='Blues')

xgb_test_cm

#confusion matrix for test data set
sns.heatmap(xgb_test_cm/np.sum(xgb_test_cm), annot=True, 
            fmt='.2%', cmap='Blues')

# Get the roc_auc score for train and test dataset
xgb_train_auc = roc_auc_score(Y_train,xgb_train_preds)
xgb_test_auc = roc_auc_score(Y_test,xgb_test_preds)

print('Train roc_auc= ',xgb_train_auc)
print('Test roc_auc= ',xgb_test_auc)

xgb_train_auc

xgb_test_auc

importances = xgb_optimal_model.feature_importances_

importance_dict_xgb = {'Feature' : list(X1.columns),
                   'Feature Importance' : importances}

importance_xgb_df = pd.DataFrame(importance_dict_xgb)

importance_xgb_df['Feature Importance'] = round(importance_xgb_df['Feature Importance'],2)

fim_df=importance_xgb_df.sort_values(by=['Feature Importance'],ascending=False)

fim_df

plt.figure(figsize=(20,20))
plt.title(' features importance')
sns.barplot(x='Feature Importance',y="Feature",data=fim_df)

"""#**Applying LogisticRegression algorithem to our DataSet**"""

from sklearn.linear_model import LogisticRegression
#C value in logistic Regression
C= [0.1,0.3,0.5,0.7,0.9,1,3,5]
#maximum iteration 
max_iter=[3000]


# HYperparameter Grid
param_lr = {'C' : C,
              'max_iter' : max_iter}

lr_model = LogisticRegression()

# Grid search
lr_grid = GridSearchCV(estimator=lr_model,
                       param_grid = param_lr,
                       cv = 5, verbose=2, scoring='roc_auc')

lr_grid.fit(X_train,Y_train)

lr_grid.best_estimator_

lr_grid.best_params_

lr_optimal_model = lr_grid.best_estimator_

# Making predictions on train and test data

train_class_preds_lr = lr_optimal_model.predict(X_train)
test_class_preds_lr = lr_optimal_model.predict(X_test)


# Get the probabilities on train and test
train_preds_lr = lr_optimal_model.predict_proba(X_train)[:,1]
test_preds_lr = lr_optimal_model.predict_proba(X_test)[:,1]

# Calculating accuracy on train and test
train_accuracy_lr = accuracy_score(Y_train,train_class_preds_lr)
test_accuracy_lr = accuracy_score(Y_test,test_class_preds_lr)

print("The accuracy on train dataset is", train_accuracy_lr)
print("The accuracy on test dataset is", test_accuracy_lr)

# Get the confusion matrices for train and test
train_cm_lr= confusion_matrix(Y_train,train_class_preds_lr)
test_cm_lr= confusion_matrix(Y_test,test_class_preds_lr)

train_cm_lr

#confusion matrix for train data set
sns.heatmap(train_cm_lr/np.sum(train_cm_lr), annot=True, 
            fmt='.2%', cmap='Blues')

test_cm_lr

#confusion matrix for test data set
sns.heatmap(test_cm_lr/np.sum(test_cm_lr), annot=True, 
            fmt='.2%', cmap='Blues')

# Get the roc_auc score for train and test dataset
train_auc_lr = roc_auc_score(Y_train,train_preds_lr)
test_auc_lr = roc_auc_score(Y_test,test_preds_lr)

print('Train roc_auc = ',train_auc_lr)
print('Test roc_auc = ',test_auc_lr)

"""#**Applying KNeighborsClassifier to our DataSet**"""

n_neighbors=[5,7,9]

# HYperparameter Grid
param_knn = {'n_neighbors' : n_neighbors}

from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier()

# Grid search
knn_grid = GridSearchCV(estimator=knn_model,
                       param_grid = param_knn,
                       cv = 5, verbose=2, scoring='roc_auc')

knn_grid.fit(X_train,Y_train)

knn_grid.best_estimator_

knn_grid.best_params_

knn_optimal_model = knn_grid.best_estimator_

# Making predictions on train and test data

train_class_preds_knn = knn_optimal_model.predict(X_train)
test_class_preds_knn = knn_optimal_model.predict(X_test)


# Get the probabilities on train and test
train_preds_knn = knn_optimal_model.predict_proba(X_train)[:,1]
test_preds_knn = knn_optimal_model.predict_proba(X_test)[:,1]

# Calculating accuracy on train and test
train_accuracy_knn = accuracy_score(Y_train,train_class_preds_knn)
test_accuracy_knn = accuracy_score(Y_test,test_class_preds_knn)

print("The accuracy on train dataset is", train_accuracy_knn)
print("The accuracy on test dataset is", test_accuracy_knn)

# Get the confusion matrices for train and test
train_cm_knn= confusion_matrix(Y_train,train_class_preds_knn)
test_cm_knn= confusion_matrix(Y_test,test_class_preds_knn)

train_cm_knn

#confusion matrix for train data set
sns.heatmap(train_cm_knn/np.sum(train_cm_knn), annot=True, 
            fmt='.2%', cmap='Blues')

test_cm_knn

#confusion matrix for test data
sns.heatmap(test_cm_knn/np.sum(test_cm_knn), annot=True, 
            fmt='.2%', cmap='Blues')

# Get the roc_auc score for train and test dataset
train_auc_knn = roc_auc_score(Y_train,train_preds_knn)
test_auc_knn = roc_auc_score(Y_test,test_preds_knn)

print('Train roc_auc_score  = ',train_auc_knn)
print('Test roc_auc_score = ',test_auc_knn)

"""#**Applying GradientBoosting Algorithem to our DataSet**"""

# Number of trees
n_estimators = [100,150]

# Maximum depth of trees
max_depth = [4,8,10]

# Minimum number of samples required to split a node
min_samples_split = [50,100]

# Minimum number of samples required at each leaf node
min_samples_leaf = [40,50]

# HYperparameter Grid
param_gb = {'n_estimators' : n_estimators,
              'max_depth' : max_depth,
              'min_samples_split' : min_samples_split,
              'min_samples_leaf' : min_samples_leaf}

# Create an instance of the  GradientBoostingClassifier
gb_model= GradientBoostingClassifier()

# Grid search
gb_grid = GridSearchCV(estimator=gb_model,
                       param_grid = param_gb,
                       cv = 3, verbose=2, scoring='roc_auc')

gb_grid.fit(X_train,Y_train)

gb_grid.best_params_

gb_grid.best_estimator_

gb_optimal_model = gb_grid.best_estimator_

# Making predictions on train and test data

gb_train_class_preds = gb_optimal_model.predict(X_train)
gb_test_class_preds = gb_optimal_model.predict(X_test)


# Get the probabilities on train and test
gb_train_preds = gb_optimal_model.predict_proba(X_train)[:,1]
gb_test_preds = gb_optimal_model.predict_proba(X_test)[:,1]

# Calculating accuracy on train and test
gb_train_accuracy = accuracy_score(Y_train,gb_train_class_preds)
gb_test_accuracy = accuracy_score(Y_test,gb_test_class_preds)

print("The accuracy on train dataset is", gb_train_accuracy)
print("The accuracy on test dataset is", gb_test_accuracy)

# Get the confusion matrices for train and test
gb_train_cm = confusion_matrix(Y_train,gb_train_class_preds)
gb_test_cm = confusion_matrix(Y_test,gb_test_class_preds )

gb_train_cm

#confusion matrix for train
sns.heatmap(gb_train_cm/np.sum(gb_train_cm), annot=True, 
            fmt='.2%', cmap='Blues')

gb_test_cm

#confusion matrix for test data
sns.heatmap(gb_test_cm/np.sum(gb_test_cm), annot=True, 
            fmt='.2%', cmap='Blues')

# Get the roc_auc score for train and test dataset
gb_train_auc = roc_auc_score(Y_train,gb_train_preds)
gb_test_auc = roc_auc_score(Y_test,gb_test_preds)

print("Train roc_auc_score = ",gb_train_auc)
print("Test roc_auc_score = ",gb_test_auc)

importances = gb_optimal_model.feature_importances_

importance_dict_gb = {'Feature' : list(X1.columns),
                   'Feature Importance' : importances}

importance_gb_df = pd.DataFrame(importance_dict_gb)
importance_gb_df

importance_gb_df['Feature Importance'] = round(importance_gb_df['Feature Importance'],2)
importance_gb_df

fim_gb_df=importance_gb_df.sort_values(by=['Feature Importance'],ascending=False)

fim_gb_df

plt.figure(figsize=(20,20))
plt.title(' features importance ')
sns.barplot(x='Feature Importance',y="Feature",data=fim_gb_df)

"""#**Applying DecisionTree algorithem to our DataSet**"""

# Maximum depth of trees
max_depth = [4,6,8]

# Minimum number of samples required to split a node
min_samples_split = [10,20,30]

# Minimum number of samples required at each leaf node
min_samples_leaf = [10,16,20]

# HYperparameter Grid
param_dt = {
              'max_depth' : max_depth,
              'min_samples_split' : min_samples_split,
              'min_samples_leaf' : min_samples_leaf}

from sklearn.tree import DecisionTreeClassifier
dt_model = DecisionTreeClassifier()

# Grid search
dt_grid = GridSearchCV(estimator=dt_model,
                       param_grid = param_dt,
                       cv = 5, verbose=2, scoring='roc_auc')

dt_grid.fit(X_train,Y_train)

dt_grid.best_estimator_

dt_grid.best_params_

dt_optimal_model = dt_grid.best_estimator_

# Making predictions on train and test data

train_class_preds_dt = dt_optimal_model.predict(X_train)
test_class_preds_dt = dt_optimal_model.predict(X_test)


# Get the probabilities on train and test
train_preds_dt = dt_optimal_model.predict_proba(X_train)[:,1]
test_preds_dt = dt_optimal_model.predict_proba(X_test)[:,1]

# Calculating accuracy on train and test
train_accuracy_dt = accuracy_score(Y_train,train_class_preds_dt)
test_accuracy_dt = accuracy_score(Y_test,test_class_preds_dt)

print("The accuracy on train dataset is", train_accuracy_dt)
print("The accuracy on test dataset is", test_accuracy_dt)

# Get the confusion matrices for train and test
train_cm_dt= confusion_matrix(Y_train,train_class_preds_dt)
test_cm_dt= confusion_matrix(Y_test,test_class_preds_dt)

train_cm_dt

#confusion matrix for train data set
sns.heatmap(train_cm_dt/np.sum(train_cm_dt), annot=True, 
            fmt='.2%', cmap='Blues')

test_cm_dt

#confusion matrix for test data
sns.heatmap(test_cm_dt/np.sum(test_cm_dt), annot=True, 
            fmt='.2%', cmap='Blues')

# Get the roc_auc score for train and test dataset
train_auc_dt = roc_auc_score(Y_train,train_preds_dt)
test_auc_dt = roc_auc_score(Y_test,test_preds_dt)

print('Train roc_auc score = ',train_auc_dt)
print('Test roc_auc score = ',test_auc_dt)

importances = dt_optimal_model.feature_importances_

importance_dict_dt = {'Feature' : list(X1.columns),
                   'Feature Importance' : importances}

importance_dt_df = pd.DataFrame(importance_dict_dt)

importance_dt_df

importance_dt_df['Feature Importance'] = round(importance_dt_df['Feature Importance'],2)
importance_dt_df

fim_dt=importance_dt_df.sort_values(by=['Feature Importance'],ascending=False)

plt.figure(figsize=(20,20))
plt.title('features importance')
sns.barplot(x='Feature Importance',y="Feature",data=fim_dt)





"""#**Model Summary**"""

from prettytable import PrettyTable 
  
# Specify the Column Names while initializing the Table 
myTable = PrettyTable(["Model Name", "Train roc_auc_score", "Test roc_auc_score", "Train accuracy_score","Test accuracy_score"]) 
  
# Add rows 
myTable.add_row(["XGBClassifier", "0.9583835622806072", "0.9282331659974463", "0.8798387971229262","0.8463206592453376"]) 
myTable.add_row(["GradientBoostingClassifier", "0.9454512107385578", "0.9258634886872759", "0.8602486717027505","0.8416943761746422"])
myTable.add_row(["RandomForestClassifier", "0.7583755701188906", "0.7522029339680062", "0.659142660931796","0.6569321960387451"]) 
myTable.add_row(["LogisticRegression", "  0.6335586602467728", " 0.6237444713851996", "  0.6016373296707268","0.5947665172762758"]) 
myTable.add_row(["KNeighborsClassifier", "0.9345105804533015", "0.8510231238558974", " 0.8484552492583749","0.7762986543192013"]) 
myTable.add_row(['DecisionTreeClassifier',' 0.7818392182507063','0.7774911129262975','0.6967325694871146','0.6948098886800637'])
  
print(myTable)